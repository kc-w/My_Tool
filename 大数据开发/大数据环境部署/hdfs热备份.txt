HDFS HA（热备、不需要secondarynamenode）
    namenode active
    namenode standby
    
问题起因：
    1.namenode宕机，这段时间所有元数据丢失，hdfs无法提供服务
    2.namenode节点，有一些服务需要升级，也需要停止服务才能升级
    
1.操作日志信息给到journalnode管理（确保两个namenode都能同步更新edits）
2.配置两个namenode
3.客户端的访问实际地址，会自动分配到active的namenode
4.两个namenode要隔离，同一时刻只有一个namenode对外提供服务


配置：
1.hdfs-site.xml:##secondarynamenode的配置可以删除
<configuration>
<property>
	<!--配置了文件块的副本数，默认就是3个，所以这里也可以不配置-->
	<name>dfs.replication</name>
	<value>3</value>
</property>
<property>
	<!--对整个文件系统需要一个统称-->
	<name>dfs.nameservices</name>
	<value>ns1</value>
</property>
<property>
	<!--指明这个文件系统的namenode有哪些-->
	<name>dfs.ha.namenodes.ns1</name>
	<value>nn1,nn2</value>
</property>
<property>
	<!--指明nn1是哪个-->
	<name>dfs.namenode.rpc-address.ns1.nn1</name>
	<value>hadoop1:8020</value>
</property>
<property>
	<!--指明nn2是那个-->
	<name>dfs.namenode.rpc-address.ns1.nn2</name>
	<value>hadoop2:8020</value>
</property>
<property>
	<!--指明nn1访问地址端口-->
	<name>dfs.namenode.http-address.ns1.nn1</name>
	<value>hadoop1:50070</value>
</property>
<property>
	<!--指明nn2访问地址端口-->
	<name>dfs.namenode.http-address.ns1.nn2</name>
	<value>hadoop2:50070</value>
</property>
<property>
	<!--共享日志在journalnode上的共享端口-->
	<name>dfs.namenode.shared.edits.dir</name>
	<value>qjournal://hadoop1:8485;hadoop2:8485;hadoop3:8485/ns1</value>
</property>
<property>
	<!--配置edits在journalnode上的保存地址-->
	<name>dfs.journalnode.edits.dir</name>
	<value>/opt/program/hadoop-2.6.0/data/jn</value>
</property>
<property>
	<!--配置proxy代理客户端-->
	<name>dfs.client.failover.proxy.provider.ns1</name>
	<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
</configuration>


	
2.core-site.xml##可以对namenode进行删除
<!--配置两个namenode的隔离策略-->
<!--sshfence方式-->
<!--使用这种方式，必须实现ssh无密码登陆-->
<configuration>
<property>
	<!--指定hadoop临时目录数据存放位置-->
	<name>hadoop.tmp.dir</name>
	<value>/opt/program/hadoop-2.6.0/data/tmp</value>
</property>
<property>
	<name>dfs.ha.fencing.methods</name>
	<value>sshfence</value>
</property>
<property>
	<name>dfs.ha.fencing.ssh.private-key-files</name>
	<value>/root/.ssh/id_rsa</value>
</property>
<property>
	<name>fs.defaultFS</name>
	<value>hdfs://ns1</value>
</property>
</configuration>



清除所有临时数据
rm -rf etc/data/tmp/*

* 最小化安装CentOS版本，需要在每一个节点都手动安装fence组件psmisc
yum -y install psmisc
	psmisc包含fuser，killall，pstree三个程序，且出现上述问题是由于我们在安装centos7的时候选择了最小化安装，默认是不安装psmics。
	fuser 显示使用指定文件或者文件系统的进程的PID。
	killall 杀死某个名字的进程，它向运行指定命令的所有进程发出信号。
	pstree 树型显示当前运行的进程。
   


	
	
自动故障转移，借助于zookeeper
1.启动时都是standby，选举一个为active
2.监控 ZKFC
	给每一个namenode都增加一个ZKFC服务
	

hdfs-site.xml:增加
打开自动故障转移
<property>
	<name>dfs.ha.automatic-failover.enabled</name>
	<value>true</value>
</property>

core-site.xml:增加
添加zookeeper的服务
<property>
	<name>ha.zookeeper.quorum</name>
	<value>hadoop1:2181,hadoop2:2181,hadoop3:2181</value>
</property>


1.关闭所有hdfs服务
sbin/stop-all.sh

2.scp同步所有节点的hdfs-site.xml和core-site.xml

3.在zookeeper下启动
bin/zkServer.sh start



4.启动zookeeper集群
	再hadoop下启动集群：
	1.分别启动所有的journalnode
	sbin/hadoop-daemon.sh start journalnode

	2.nn1格式化并启动
	bin/hdfs namenode -format
	sbin/hadoop-daemon.sh start namenode

	3.在nn2上，同步nn1的元数据信息,再启动
	bin/hdfs namenode -bootstrapStandby
	sbin/hadoop-daemon.sh start namenode

	4.分别启动所有的datanode节点
	sbin/hadoop-daemon.sh start datanode

sbin/start-dfs.sh
	
sbin/start-yarn.sh ##启动yarn相关服务
sbin/mr-jobhistory-daemon.sh  start  historyserver ##启动日志相关服务

5.nn1节点初始化HA在zookeeper中的状态
bin/hdfs zkfc -formatZK -force


6.启动zkfc，先在哪台节点启动zkfc，那么哪台就是active
sbin/hadoop-daemon.sh start zkfc


下载问题
进入C:\Windows\System32\drivers\etc目录,打开hosts文件,在底下加上
192.168.1.131 hadoop1
192.168.1.132 hadoop2
192.168.1.133 hadoop3

