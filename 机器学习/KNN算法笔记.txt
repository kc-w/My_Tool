KNN(K-近邻)算法
KNN算法是一个用于对数据样本进行分类预测的算法
有监督学习
无监督学习

有参数学习
	算法本身会对数据的规律进行假设
	线性回归 y=ax+b
	X(姓名 年龄 月收入) y(是否贷款) label
	y=ax+b
	a 斜率
	b 截距
	模型参数

无参数学习
	算法本身会对数据的规律(分布)进行假设
	KNN

KNN算法
	KNN算法就是根据样本点之前的距离来对新的样本进行分类
	K就表示要取离新样本点最近的K个样本进行分类决策


作业
	对KNN算法进行封装
	class KNNClassifer
	初始化参数K
	fit(train_data, train_label)
	predict(new_data) 返回预测的分类结果
	出入的参数是二维矩阵


机器学习中的两种类型的参数
	1.超参数
		在训练模型之前，需要设置的参数

	2.模型参数
		通过样本训练出的参数

算法模型评测
	我们如何对已经训练好的算法进行评测？
	考量算法模型的泛化能力

	训练集

KNN算法中的超参数
	1.K值
	2.距离权重
	3.p值

对于寻找最优超参数的过程，称之为网络搜索
	GridSearchCV
	Grid 网格
	Search 搜索
	CV Cross Validation(交叉验证)

KNN算法的优缺点
	优点：
		简单、偏差较低

	缺点：
		欧式距离
		维度灾难
		计算量巨大


归一化
	统一不同指标的取值范围
	统一所有指标的量纲
	一般来说，在对模型进行训练前，都要对数据进行归一化操作

		
