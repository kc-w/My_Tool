1:打开cmd或终端cd到你的项目目录下,在命令行输入'scrapy startproject 爬虫名'找到目录用ide打开.
首先创建一个类，并继承scrapy的一个子类：scrapy.Spider  或者是其他蜘蛛类型；
然后定义一个蜘蛛名，name=“”  后面我们运行的话需要用到；
定义我们需要爬取的网址；
继承scrapy的一个方法：start_requests(self)，这个方法的作用就是通过上面定义的链接去爬取页面，简单理解就是下载页面。